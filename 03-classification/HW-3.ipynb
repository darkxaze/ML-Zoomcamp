{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110f8246",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly.\n",
    "> That's fine.\n",
    "> Select the option that's closest to your solution.\n",
    "> If it's exactly in between two options, select the higher value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9d959",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For categorical features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44651416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-26 16:30:37--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv.1’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-11-26 16:30:37 (6.36 MB/s) - ‘course_lead_scoring.csv.1’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "df =pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f566022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193075f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e240300f",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- `retail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9f58f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0806f8e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`\n",
    "\n",
    "Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec14bc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3c0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['number_of_courses_viewed','annual_income','interaction_count','lead_score' ]\n",
    "df_num = df[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477e9bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number_of_courses_viewed  annual_income  interaction_count  lead_score\n",
       "0                            1        79450.0                  4        0.94\n",
       "1                            1        46992.0                  1        0.80\n",
       "2                            5        78796.0                  3        0.69\n",
       "3                            2        83843.0                  1        0.87\n",
       "4                            3        85012.0                  3        0.62\n",
       "...                        ...            ...                ...         ...\n",
       "1457                         1            NaN                  4        0.53\n",
       "1458                         3        65259.0                  2        0.24\n",
       "1459                         1        45688.0                  3        0.02\n",
       "1460                         5        71016.0                  0        0.25\n",
       "1461                         3        92855.0                  3        0.41\n",
       "\n",
       "[1462 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a79e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_of_courses_viewed</td>\n",
       "      <td>0.435914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interaction_count</td>\n",
       "      <td>0.374573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lead_score</td>\n",
       "      <td>0.193673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annual_income</td>\n",
       "      <td>0.078256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  coefficient\n",
       "0  number_of_courses_viewed     0.435914\n",
       "2         interaction_count     0.374573\n",
       "3                lead_score     0.193673\n",
       "1             annual_income     0.078256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[num].corrwith(df['converted']).to_frame('coefficient').reset_index().sort_values('coefficient',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927bc9d",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `converted` is not in your dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc090ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages (from scikit-learn) (2.3.5)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd33dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['converted']\n",
    "del df['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b26ccbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_full_train, df_test, y_full_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "df_train, df_val, y_train, y_val = train_test_split(df_full_train, y_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f4dc2",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- `industry`\n",
    "- `location`\n",
    "- `lead_source`\n",
    "- `employment_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba137572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lead_source', 'industry', 'employment_status', 'location'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17710cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fdf6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_cols] = df[categorical_cols].fillna('NA')\n",
    "df[num] = df[num].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5eae18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.035396\n",
       "employment_status    0.012938\n",
       "industry             0.011575\n",
       "location             0.004464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "mi = df_train[categorical_cols].fillna('NA').apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057be368",
   "metadata": {},
   "source": [
    "\n",
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5752d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856655290102389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Identify categorical & numerical columns\n",
    "cat_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "num_cols = [\n",
    "    'number_of_courses_viewed', 'annual_income', \n",
    "    'interaction_count', 'lead_score', 'converted'\n",
    "]\n",
    "\n",
    "# 2. Preprocessing: One-hot encode categorical features\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'   # keep numerical columns\n",
    ")\n",
    "\n",
    "# 3. Build full pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess),\n",
    "    ('logreg', LogisticRegression(C=1.0,\n",
    "    max_iter=1000,\n",
    "    random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "df_train[categorical_cols] = df_train[categorical_cols].fillna('NA')\n",
    "df_train[num] = df_train[num].fillna(0)\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_val)\n",
    "acc = accuracy_score(y_val,y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964fa77",
   "metadata": {},
   "source": [
    "\n",
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5b2d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when dropping 'industry': 0.8396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when dropping 'employment_status': 0.8328\n",
      "Accuracy when dropping 'lead_score': 0.8259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = pd.DataFrame(columns=['eliminated_feature', 'accuracy', 'difference'])\n",
    "\n",
    "cat_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "num_cols = [\n",
    "    'number_of_courses_viewed', \n",
    "    'annual_income', \n",
    "    'interaction_count', \n",
    "    'lead_score'\n",
    "]\n",
    "\n",
    "\n",
    "X_train = df_train[cat_cols + num_cols].copy()\n",
    "X_val = df_val[cat_cols + num_cols].copy()\n",
    "\n",
    "cols = cat_cols + num_cols  # all features\n",
    "\n",
    "eliminate = [\n",
    " 'industry',\n",
    " 'employment_status',\n",
    " 'lead_score']\n",
    "\n",
    "for col in eliminate:\n",
    "    \n",
    "    # Drop feature from train and val\n",
    "    X_train_drop = X_train.drop(columns=[col])\n",
    "    X_val_drop   = X_val.drop(columns=[col])\n",
    "    \n",
    "    # Adjust categorical column list\n",
    "    cat_cols_drop = [c for c in cat_cols if c != col]\n",
    "    \n",
    "    # Preprocessor\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_drop)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocess),\n",
    "        ('logreg', LogisticRegression(C=1,\n",
    "        max_iter=1000,\n",
    "        random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    model.fit(X_train_drop, y_train)\n",
    "    y_pred = model.predict(X_val_drop)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.loc[len(scores)] = [col, acc, 0.856655290102389 - acc]\n",
    "    print(f\"Accuracy when dropping '{col}': {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6378ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eliminated_feature</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>industry</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.017065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employment_status</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.023891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lead_score</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.030717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eliminated_feature  accuracy  difference\n",
       "0           industry  0.839590    0.017065\n",
       "1  employment_status  0.832765    0.023891\n",
       "2         lead_score  0.825939    0.030717"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d7491",
   "metadata": {},
   "source": [
    "\n",
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83fffdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C equal to 0.01 Accuracy is : 0.8122866894197952\n",
      "For C equal to 0.1 Accuracy is : 0.8430034129692833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C equal to 1 Accuracy is : 0.856655290102389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastavirs/ML-Zoomcamp/.myvenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C equal to 10 Accuracy is : 0.8532423208191127\n",
      "For C equal to 100 Accuracy is : 0.8532423208191127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Identify categorical & numerical columns\n",
    "cat_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "num_cols = [\n",
    "    'number_of_courses_viewed', 'annual_income', \n",
    "    'interaction_count', 'lead_score', 'converted'\n",
    "]\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "# 2. Preprocessing: One-hot encode categorical features\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "        ],\n",
    "        remainder='passthrough'   # keep numerical columns\n",
    "    )\n",
    "\n",
    "    # 3. Build full pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocess),\n",
    "        ('logreg', LogisticRegression(C = C,\n",
    "        max_iter=1000,\n",
    "        random_state=42))\n",
    "    ])\n",
    "\n",
    "\n",
    "    df_train[categorical_cols] = df_train[categorical_cols].fillna('NA')\n",
    "    df_train[num] = df_train[num].fillna(0)\n",
    "    model.fit(df_train,y_train)\n",
    "    y_pred = model.predict(df_val)\n",
    "    acc = accuracy_score(y_val,y_pred)\n",
    "    print(f\"For C equal to {C} Accuracy is :\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
